---
description:
globs:
alwaysApply: false
---
# WatchBuddy Chrome Extension - Comprehensive Codebase Documentation

## Project Overview
WatchBuddy is an intelligent Chrome extension that provides AI-powered voice interaction for YouTube videos. [Users can ask questions about video content using voice input and receive intelligent responses based on the video's subtitles][[memory:4708356964196961831]]. The extension supports both automatic subtitle extraction and manual subtitle upload as a fallback mechanism.

## Project Core Features
- **Smart Voice Activity Detection (VAD)**: Neural network-based speech detection using @ricky0123/vad-web
- **YouTube Subtitle Extraction**: Encrypted API communication with downsub.com
- **Manual Subtitle Upload**: SRT file drag-and-drop with real-time preview
- **OpenAI Integration**: GPT-4o-mini with prefix caching optimization (30-50% cost reduction)
- **Text-to-Speech**: Browser-native speech synthesis
- **Multi-Video Conversation**: Per-video conversation history management
- **Analytics**: Optional usage statistics with Google Analytics 4

## Chrome Extension Core Files

### [manifest.json](mdc:chrome-extension/manifest.json)
**Purpose**: Extension configuration and permissions
**Key Settings**:
- `manifest_version: 3` - Uses latest Chrome extension architecture
- `permissions: ["activeTab", "storage"]` - Minimal required permissions
- `host_permissions` - YouTube, OpenAI, downsub.com, Google Analytics
- `content_scripts` - Loads 8 utility files + main content.js
- `background.service_worker` - Points to background.js

### [content.js](mdc:chrome-extension/src/content.js) - Main Content Script (1112 lines)
**Purpose**: Primary interface injected into YouTube pages

**Main Class**: `YouTubeVoiceAssistant`

**Key Properties**:
- `subtitleExtractor: SubtitleExtractor` - Handles subtitle fetching
- `aiAssistant: OpenAIVoiceAssistant` - AI interaction manager
- `currentVideoId: string` - Currently active video ID
- `subtitlesData: object` - Processed subtitle data
- `floatingContainer: HTMLElement` - UI container element
- `floatingButton: HTMLElement` - Voice activation button
- `manualSubtitle: object` - Manually uploaded subtitle data
- `contextMaxWords: number` - Subtitle context length (default: 28)
- `analytics: Analytics` - Usage tracking instance

**Core Methods**:
- `init()` - Initialize assistant and setup listeners
- `setup()` - Create UI and load subtitles for current video
- `setupMessageListener()` - Handle messages from background/popup
- `createFloatingButton()` - Generate draggable voice activation button
- `setupDragAndClick()` - Handle button drag/click interactions
- `handleVoiceQuery()` - Process voice input and generate AI responses
- `preloadSubtitles()` - Attempt automatic subtitle extraction
- `loadSubtitles(videoId)` - Load subtitles from multiple sources
- `getCurrentSubtitleContext(currentTime)` - Extract relevant subtitle context
- `parseSubtitleToTranscript(srtContent)` - Convert SRT to full text
- `parseSubtitleToTimestamps(srtContent)` - Convert SRT to timestamped array
- `observeNavigation()` - Detect YouTube page changes
- `cleanup()` - Clean up resources and event listeners

**Message Handlers**:
- `reload_assistant` - Reinitialize the assistant
- `activate_voice_assistant` - Trigger voice input
- `manual_subtitle_uploaded` - Handle manual subtitle data
- `analytics_setting_changed` - Update analytics preferences

### [background.js](mdc:chrome-extension/src/background.js) - Service Worker (598 lines)
**Purpose**: Background service worker for API calls and message passing

**Global Variables**:
- `currentVideoSubtitles: object` - Stores current video subtitle data
  - `videoId: string` - Video identifier
  - `transcript: string` - Full text content
  - `language: string` - Subtitle language
  - `timestamps: array` - Timestamped subtitle entries
  - `source: string` - 'api'|'manual' source indicator

**Core Functions**:
- `fetchSubtitles(url, headers, sendResponse)` - CORS proxy for subtitle API
- `downloadSubtitleContent(url, sendResponse)` - Download subtitle files
- `chatWithOpenAI(messages, videoContext, sendResponse)` - AI conversation proxy
- `sendAnalyticsEvent(payload, measurementId, apiSecret, sendResponse)` - Google Analytics proxy
- `getApiKey(sendResponse)` - Retrieve stored OpenAI API key
- `checkPermissions(sendResponse)` - Validate extension permissions
- `cleanupStorage()` - Remove expired data (conversation history, manual subtitles)
- `notifyAllYouTubeTabs()` - Send messages to all YouTube tabs

**Message Actions**:
- `fetch_subtitles` - Proxy subtitle API requests
- `subtitles_ready` - Store subtitle data globally
- `chat_with_openai` - Handle AI conversation requests
- `get_current_subtitles` - Return subtitle status for popup
- `send_analytics` - Proxy Google Analytics events

### [popup.js](mdc:chrome-extension/src/popup.js) - Extension Popup (685 lines)
**Purpose**: Extension popup interface for settings and manual subtitle management

**Core Functions**:
- `initPopup()` - Initialize popup interface and load settings
- `loadApiKey()` - Load saved OpenAI API key
- `saveApiKey()` - Validate and save OpenAI API key
- `loadVoiceSettings()` - Load enhanced voice mode preference
- `saveVoiceSettings()` - Save voice recording preferences
- `loadPrivacySettings()` - Load analytics consent setting
- `savePrivacySettings()` - Save privacy preferences
- `loadCustomPrompt()` - Load custom AI prompt or use default
- `saveCustomPrompt()` - Save custom AI system prompt
- `loadSubtitleStatus()` - Check current video subtitle availability
- `handleFileUpload(file)` - Process SRT file upload
- `saveSubtitleContent(subtitleContent)` - Save manual subtitle data
- `clearSubtitle()` - Remove manual subtitle data
- `isValidSRTFormat(content)` - Validate SRT file format
- `testConnection()` - Test OpenAI API connectivity
- `bindEventListeners()` - Setup UI event handlers

**UI Event Handlers**:
- File drop/upload for manual subtitles
- API key visibility toggle
- Settings save/reset buttons
- Test connection button

### [popup.html](mdc:chrome-extension/src/popup.html) - Popup Interface (528 lines)
**Purpose**: HTML structure for extension popup

**Key Sections**:
- Header with extension branding
- API key configuration section
- Voice settings (enhanced mode toggle)
- Privacy settings (analytics consent)
- Custom AI prompt configuration
- Manual subtitle upload interface
- Status display and connection testing

**UI Components**:
- Input fields with validation styling
- Toggle switches for settings
- File upload with drag-and-drop support
- Status messages with type-specific styling
- Responsive design for different screen sizes

## Utility Libraries

### [subtitle-extractor.js](mdc:chrome-extension/src/utils/subtitle-extractor.js) - Subtitle API Client (519 lines)
**Purpose**: YouTube subtitle extraction using encrypted downsub.com API

**Main Class**: `SubtitleExtractor`

**Key Properties**:
- `SECRET_KEY: string` - "zthxw34cdp6wfyxmpad38v52t3hsz6c5"
- `API: string` - "https://get-info.downsub.com/"
- `CryptoJS: object` - Cryptographic library reference
- `formatJson: object` - AES encryption/decryption formatter

**Core Methods**:
- `_encode(payload, options)` - AES-256-CBC encryption with random IV/salt
- `_decode(payload, options)` - AES decryption
- `_toBase64(payload)` - Custom base64 encoding (+ → -, / → _, remove =)
- `_toBinary(base64)` - Custom base64 decoding
- `_generateData(videoId)` - Create encrypted API request payload
- `_decodeArray(result)` - Decode subtitle URLs from API response
- `getSubtitles(videoId)` - Main subtitle fetching method
- `downloadSubtitleContent(subtitle, format)` - Download subtitle content
- `parseSRTToTimestamps(srtContent)` - Parse SRT format to timestamped array
- `parseXMLToTimestamps(xmlContent)` - Parse XML format to timestamped array
- `getFullTranscriptFromContent(content)` - Extract full text from subtitle content
- `getFirstEnglishSubtitle(videoId)` - Get English subtitles specifically

**Encryption Process**:
1. Generate random salt (64-bit) and IV (128-bit)
2. Apply AES-256-CBC encryption with custom password
3. Format as JSON with {ct, iv, s} fields
4. Apply custom base64 encoding

### [voice-recorder.js](mdc:chrome-extension/src/utils/voice-recorder.js) - Smart Voice Recording (382 lines)
**Purpose**: VAD-based intelligent voice recording

**Main Class**: `SmartVoiceRecorder`

**Key Properties**:
- `vadInstance: MicVAD` - Voice Activity Detection instance
- `isRecording: boolean` - Recording state
- `audioChunks: array` - Recorded audio data
- `microphoneReady: boolean` - Microphone initialization status
- `vadInitialized: boolean` - VAD initialization status
- `isPaused: boolean` - Whether VAD is paused (enhanced mode)

**Core Methods**:
- `initialize()` - Initialize VAD with neural network model
- `startSmartRecording()` - Begin VAD-based recording
- `handleSpeechStart()` - Process speech detection
- `handleSpeechEnd(vadAudio)` - Process speech completion
- `float32ArrayToBlob(float32Array)` - Convert VAD audio to WAV blob
- `createWavHeader(sampleCount)` - Generate WAV file header
- `getEnhancedVoiceMode()` - Check enhanced mode setting
- `forceDestroy()` - Clean up VAD resources
- `setCallbacks(callbacks)` - Set event callbacks

**VAD Configuration**:
- `mode: 'v5'` - VAD model version
- `positiveSpeechThreshold: 0.5` - Speech detection sensitivity
- `negativeSpeechThreshold: 0.35` - Silence detection sensitivity
- `minSpeechFrames: 16` - Minimum frames for speech
- `redemptionFrames: 40` - Prevent false negatives
- `submitUserSpeechOnPause: false` - Don't auto-submit on pause

**Enhanced Mode**: Keeps VAD paused between recordings to avoid 1.0-1.7s audio loss during reinitialization

### [openai-client.js](mdc:chrome-extension/src/utils/openai-client.js) - AI Integration (1158 lines)
**Purpose**: OpenAI API integration with conversation management

**Main Class**: `OpenAIVoiceAssistant`

**Key Properties**:
- `apiKey: string` - OpenAI API key
- `baseURL: string` - 'https://api.openai.com/v1'
- `videoConversations: Map` - Per-video conversation history
- `currentVideoId: string` - Active video identifier
- `maxHistoryLength: number` - Max 20 conversations per video
- `maxVideoCount: number` - Max 10 videos cached
- `audioCache: Map` - Audio data cache (legacy)

**Core Methods**:
- `switchToVideo(videoId)` - Change conversation context
- `addOptimizedConversationHistory(role, content, audioBase64, audioTranscript, context, audioId)` - Add conversation with context optimization
- `buildOptimizedTextMessages(userQuestion, context)` - Build message array with static/dynamic separation
- `processVoiceQuerySmart(context, onStatusUpdate)` - Main voice processing with VAD
- `processVoiceQuery(context, onStatusUpdate)` - Fallback voice processing (5-second recording)
- `transcribeAudio(audioBlob, options)` - Convert speech to text
- `optimizedAudioCompletion(audioBlob, context)` - Complete audio interaction workflow
- `recordAudioSmart(onStatusUpdate)` - Smart VAD-based recording
- `recordAudio(duration)` - Traditional timed recording
- `cleanupOldConversations()` - Remove old conversation history (LRU)
- `resetVideoConversation(videoId)` - Clear specific video's history
- `blobToBase64(blob)` - Convert audio blob to base64
- `logTimingStats(timings, operation)` - Performance logging

**Message Optimization**:
- **Static System Message**: Video metadata + full transcript (cacheable)
- **Dynamic Context Message**: Current time + relevant subtitles (per turn)
- **Conversation History**: Maintained per video with 20-message limit

**Performance Features**:
- OpenAI prefix caching for 30-50% cost reduction
- Per-video conversation isolation
- LRU cleanup for memory management
- Timing statistics for performance monitoring

### [analytics.js](mdc:chrome-extension/src/utils/analytics.js) - Usage Statistics (303 lines)
**Purpose**: Anonymous usage tracking with Google Analytics 4

**Main Class**: `Analytics`

**Key Properties**:
- `MEASUREMENT_ID: string` - 'G-E0X90GKJ41'
- `API_SECRET: string` - Google Analytics API secret
- `clientId: string` - Anonymous user identifier
- `sessionId: string` - Session identifier
- `enabled: boolean` - User consent status

**Core Methods**:
- `init()` - Initialize analytics with consent check
- `initClientId()` - Generate/retrieve anonymous client ID
- `sendEvent(eventName, parameters)` - Send event to Google Analytics
- `trackInstall()` - Record first-time installation
- `trackVoiceQuery(success)` - Record voice interaction
- `trackSubtitleLoad(source, fromCache)` - Record subtitle loading
- `trackError(errorType, errorMessage)` - Record error events
- `setEnabled(enabled)` - Update user consent
- `generateClientId()` - Create UUID-format anonymous ID

**Event Types**:
- `extension_install` - First-time installation
- `voice_query_success` / `voice_query_error` - Voice interactions
- `subtitle_load` - Subtitle fetching (api/manual, cached/fresh)
- `error_occurred` - Error tracking with categorization

**Privacy Features**:
- User consent required (default enabled, can be disabled)
- Anonymous client IDs only
- No personal information collected
- Extension context validation

### [logger.js](mdc:chrome-extension/src/utils/logger.js) - Debug Logging (77 lines)
**Purpose**: Centralized logging system with debug control

**Main Class**: `Logger`

**Key Properties**:
- `IS_DEBUG: boolean` - Debug mode flag (false for production)

**Core Methods**:
- `log(...args)` - General logging (debug mode only)
- `error(...args)` - Error logging (always active)
- `warn(...args)` - Warning logging (debug mode only)
- `debug(...args)` - Debug logging (debug mode only)
- `info(...args)` - Info logging (debug mode only)
- `createDebugPanel(containerId, content)` - Create floating debug panel

**Usage Pattern**:
```javascript
Logger.log('Regular debug information');
Logger.error('Error that should always be logged');
Logger.warn('Warning message');
```

## Styling and UI

### [styles.css](mdc:chrome-extension/src/styles.css) - UI Styling (312 lines)
**Purpose**: Complete styling for floating button and status display

**Key Components**:

**Floating Container** (`.yva-floating-container`):
- Fixed positioning with high z-index (2147483647)
- Flex layout with column direction
- Default position: top: 20px, left: 75vw

**Floating Button** (`.yva-floating-button`):
- 60px circular button with gradient background
- Hover/active/dragging state animations
- Scale transforms and shadow effects
- Touch-action: none for mobile support

**Status Display** (`.yva-status-display`):
- Backdrop blur with semi-transparent background
- Type-specific colors (info, recording, processing, playing, success, error)
- Pulse animation for recording state
- Responsive max-width and positioning

**State Classes**:
- `.info` - Blue background for general information
- `.recording` - Red background with pulse animation
- `.processing` - Orange background for processing
- `.playing` - Green background for audio playback
- `.success` - Green background for success messages
- `.error` - Red background for error messages

**Responsive Design**:
- Mobile breakpoint at 768px
- Smaller button size (50px) on mobile
- Adjusted spacing and font sizes
- Accessibility features (high contrast, reduced motion support)

## Build and Release Scripts

### [package.json](mdc:package.json) - Project Configuration
**Purpose**: Node.js project configuration and scripts

**Scripts**:
- `npm run dev` - Restore development configuration
- `npm run release` - Prepare release build
- `npm run package` - Create release ZIP file

**Dependencies**:
- `archiver: ^6.0.1` - ZIP file creation for releases

### [create-release.js](mdc:create-release.js) - Release Packaging (92 lines)
**Purpose**: Automated ZIP creation for Chrome Web Store

**Core Functions**:
- Read version from manifest.json
- Create releases/ directory
- Package chrome-extension/ contents
- Exclude test files and debug content
- Add documentation files (README.md, privacy_policy.html)
- Generate release ZIP with version naming

**Excluded Files**:
- `test-*.html` - Test files
- `DEBUG_GUIDE.md` - Debug documentation
- `.git/` - Git metadata
- `.DS_Store` - macOS system files

## Data Storage Patterns

### Chrome Storage Usage
**Sync Storage** (synced across devices):
- `openai_api_key` - OpenAI API key
- `enhanced_voice_mode` - VAD mode preference
- `analytics_enabled` - Usage statistics consent
- `custom_prompt` - Custom AI system prompt

**Local Storage** (device-specific):
- `conversation_history` - AI conversation history (7-day retention)
- `manual_subtitle_{videoId}` - Manual subtitle data (30-day retention)
- `analytics_client_id` - Anonymous analytics identifier
- `install_tracked` - First-time installation flag
- `button_position_{videoId}` - Floating button position per video

### Automatic Cleanup
- **Conversation History**: 7-day automatic cleanup
- **Manual Subtitles**: 30-day automatic cleanup
- **Audio Cache**: 5-minute interval cleanup for expired entries
- **Old Video Conversations**: LRU cleanup when >10 videos cached

## Security Implementation

### Content Security Policy
- No external script execution in content scripts
- All libraries loaded locally (crypto-js.min.js, ort.js, vad-web.js)
- CORS proxy through background service worker
- Secure API key storage in Chrome sync storage

### API Key Management
- Stored encrypted in Chrome sync storage
- Never exposed in content scripts
- Transmitted only to authorized endpoints (OpenAI API)
- Validation on both client and server side

### Permission Management
- Minimal required permissions in manifest
- Runtime permission validation
- Graceful degradation when permissions unavailable
- User consent for analytics tracking

## Error Handling and Fallbacks

### Layered Error Handling
1. **Function Level**: Try-catch blocks for all async operations
2. **Promise Level**: Rejection handling for all API calls
3. **UI Level**: User-friendly error messages in status display
4. **Analytics Level**: Error event tracking for debugging

### Fallback Mechanisms
- **VAD Failure** → Traditional 5-second recording
- **API Subtitle Failure** → Manual subtitle upload option
- **Network Failure** → Cached subtitle data
- **OpenAI Rate Limits** → User notification with retry option
- **Microphone Access Denied** → Clear user guidance

### Recovery Strategies
- **Extension Context Invalidation** → Automatic reinitialization
- **YouTube Navigation** → Automatic content script reloading
- **API Key Issues** → Clear validation feedback
- **Storage Quota Exceeded** → Automatic cleanup of old data

## Performance Optimizations

### Memory Management
- Automatic cleanup of large objects (audio data, conversation history)
- Efficient subtitle storage with timestamp indexing
- Limited conversation history per video (20 messages max)
- LRU eviction for video conversation cache

### Network Optimization
- OpenAI prefix caching for 30-50% token cost reduction
- Efficient API request batching where possible
- Response caching for repeated subtitle requests
- Minimal header overhead in API calls

### UI Optimization
- Input protection during periodic updates
- Focus detection to skip updates during user interaction
- Debounced position saving for floating button
- Lazy loading of heavy libraries (VAD, ONNX Runtime)

This comprehensive documentation covers the entire WatchBuddy codebase structure, providing detailed information about each file's purpose, classes, functions, and key variables for effective development and maintenance.
